@inproceedings{baker2011bayesian,
  title={Bayesian theory of mind: Modeling joint belief-desire attribution},
  author={Baker, Chris and Saxe, Rebecca and Tenenbaum, Joshua},
  booktitle={Proceedings of the annual meeting of the cognitive science society},
  volume={33},
  number={33},
  year={2011}
}

@article{hauskrecht2000value,
  title={Value-function approximations for partially observable Markov decision processes},
  author={Hauskrecht, Milos},
  journal={Journal of artificial intelligence research},
  volume={13},
  pages={33--94},
  year={2000}
}

@article{shum2019theory,
  title={Theory of Minds: Understanding Behavior in Groups Through Inverse Planning},
  author={Shum, Michael and Kleiman-Weiner, Max and Littman, Michael L and Tenenbaum, Joshua B},
  journal={arXiv preprint arXiv:1901.06085},
  year={2019}
}

@article{seaman2018modeling,
  title={Modeling Theory of Mind for Autonomous Agents with Probabilistic Programs},
  author={Seaman, Iris Rubi and van de Meent, Jan-Willem and Wingate, David},
  journal={arXiv preprint arXiv:1812.01569},
  year={2018}
}


@article{todorov2009efficient,
  title = {Efficient Computation of Optimal Actions.},
  volume = {106},
  issn = {0710743106},
  doi = {10.1073/pnas.0710743106},
  abstract = {Optimal choice of actions is a fundamental problem relevant to fields as diverse as neuroscience, psychology, economics, computer science, and control engineering. Despite this broad relevance the abstract setting is similar: we have an agent choosing actions over time, an uncertain dynamical system whose state is affected by those actions, and a performance criterion that the agent seeks to optimize. Solving problems of this kind remains hard, in part, because of overly generic formulations. Here, we propose a more structured formulation that greatly simplifies the construction of optimal control laws in both discrete and continuous domains. An exhaustive search over actions is avoided and the problem becomes linear. This yields algorithms that outperform Dynamic Programming and Reinforcement Learning, and thereby solve traditional problems more efficiently. Our framework also enables computations that were not possible before: composing optimal control laws by mixing primitives, applying deterministic methods to stochastic systems, quantifying the benefits of error tolerance, and inferring goals from behavioral data via convex optimization. Development of a general class of easily solvable problems tends to accelerate progress--as linear systems theory has done, for example. Our framework may have similar impact in fields where optimal choice of actions is relevant.},
  number = {28},
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  author = {Todorov, Emanuel},
  year = {2009},
  pages = {11478-11483},
  file = {/Users/janwillem/Zotero/storage/XGGQWP85/Todorov - 2009 - Efficient computation of optimal actions.pdf}
}

@article{lavalle1998rapidly,
  title={Rapidly-exploring random trees: A new tool for path planning},
  author={LaValle, Steven M},
  year={1998},
  publisher={Citeseer}
}